
\documentclass[11pt]{exam} % https://www.ctan.org/pkg/exam?lang=en

\usepackage[lmargin=1.in,rmargin=1.in,tmargin=1.in,bmargin=1in]{geometry}
\usepackage{setspace}
\usepackage[pdftex]{graphicx}
\usepackage{titling}
\usepackage[
	pdfauthor={Brian Weinstein},
	pdftitle={Homework 1},
	bookmarks=true,
	colorlinks=true,
	linkcolor=blue,
	urlcolor=blue,
	citecolor=blue,
	pdftex,
	linktocpage=true
	]{hyperref}
\usepackage[textsize=tiny]{todonotes}
\usepackage{float}
\setlength\parindent{0pt} % or 1em
\usepackage{lipsum}
\usepackage{amsmath}
\usepackage{caption}


\qformat{\textbf{Problem \thequestion: \thequestiontitle}\quad \hfill}


\pagestyle{headandfoot}
\runningheadrule
\firstpageheader{}{}{}
\runningheader{\theauthor}{\thetitle}{\thedate}
\firstpagefooter{}{\thepage}{}
\runningfooter{}{\thepage}{}


\usepackage{xcolor}
\usepackage{adjustbox}
\usepackage{verbatim}
\definecolor{shadecolor}{rgb}{.9, .9, .9}

\newenvironment{code}%
   {\par\noindent\adjustbox{margin=1ex,bgcolor=shadecolor,margin=0ex \medskipamount}\bgroup\minipage\linewidth\verbatim}%
   {\endverbatim\endminipage\egroup}

\newenvironment{codeSmall}%
   {\par\noindent\adjustbox{margin=1ex,bgcolor=shadecolor,margin=0ex \medskipamount}\bgroup\minipage\linewidth\verbatim\footnotesize}%
   {\endverbatim\endminipage\egroup}

\newcommand{\ramsey}{\href{http://www.statisticalsleuth.com/}{Ramsey }}



\begin{document}


\title{STAT W4201 001, Homework 7}
\author{Brian Weinstein (bmw2148)}
\date{Mar 28, 2016}
\maketitle

Code is attached here and also posted at \href{https://github.com/BrianWeinstein/advanced-data-analysis}{https://github.com/BrianWeinstein/advanced-data-analysis}. Where relevant, code snippets and output are are included in-line.

\begin{questions}


\titledquestion{\ramsey 10.21}

Let

$$
\mathbf{Y} = 
  \begin{bmatrix}
    Y_1 \\
    Y_2 \\
    \vdots \\
    Y_n
  \end{bmatrix}
, \quad
\mathbf{X}=
  \begin{bmatrix}
    1 & X_{11} & X_{12} & \cdots & X_{1p} \\
    1 & X_{21} & X_{22} & \cdots & X_{2p} \\
    \vdots & \vdots & \vdots &  & \vdots \\
    1 & X_{n1} & X_{n2} & \cdots & X_{np} \\
  \end{bmatrix}
, \quad \text{and \ }
\mathbf{b} = 
  \begin{bmatrix}
    \beta_0 \\
    \beta_1 \\
    \vdots \\
    \beta_p
  \end{bmatrix} .
$$

By deconstructing $(\mathbf{X}^T \mathbf{X}) \mathbf{b} = \mathbf{X}^T \mathbf{Y}$ we find the set of normal equations:
\begin{gather*}
(\mathbf{X}^T \mathbf{X}) \mathbf{b} = \mathbf{X}^T \mathbf{Y} \\ 
\Rightarrow \left(
  \begin{bmatrix}
  	1 & 1 & \cdots & 1 \\
  	X_{11} & X_{21} & \cdots & X_{n1} \\
  	X_{12} & X_{22} & \cdots & X_{n2} \\
    \vdots & \vdots &  & \vdots \\
  	X_{1p} & X_{2p} & \cdots & X_{np} \\
  \end{bmatrix}
  \begin{bmatrix}
    1 & X_{11} & X_{12} & \cdots & X_{1p} \\
    1 & X_{21} & X_{22} & \cdots & X_{2p} \\
    \vdots & \vdots & \vdots &  & \vdots \\
    1 & X_{n1} & X_{n2} & \cdots & X_{np} \\
  \end{bmatrix}
\right)
\begin{bmatrix}
    \beta_0 \\
    \beta_1 \\
    \vdots \\
    \beta_p
  \end{bmatrix}
=
  \begin{bmatrix}
  	1 & 1 & \cdots & 1 \\
  	X_{11} & X_{21} & \cdots & X_{n1} \\
  	X_{12} & X_{22} & \cdots & X_{n2} \\
    \vdots & \vdots &  & \vdots \\
  	X_{1p} & X_{2p} & \cdots & X_{np} \\
  \end{bmatrix}
  \begin{bmatrix}
    Y_1 \\
    Y_2 \\
    \vdots \\
    Y_n
  \end{bmatrix}
\\
\Rightarrow \begin{bmatrix}
  	n & \sum X_{i1} & \sum X_{i2} & \cdots & \sum X_{ip} \\
  	\sum X_{i1} & \sum X_{i1}^2 & \sum X_{i1} X_{i2 } & \cdots & \sum X_{i1} X_{ip} \\
  	\sum X_{i2} & \sum X_{i2} X_{i1} & \sum X_{i2}^2 & \cdots & \sum X_{i2} X_{ip} \\
  	\vdots & \vdots & \vdots &  & \vdots \\
  	\sum X_{ip} & \sum X_{ip} X_{i1} & \sum X_{ip} X_{i2} & \cdots & \sum X_{ip}^2 \\
  \end{bmatrix}
  \begin{bmatrix}
    \beta_0 \\
    \beta_1 \\
    \vdots \\
    \beta_p
  \end{bmatrix}
=
  \begin{bmatrix}
    \sum Y_{i} \\
    \sum X_{i1} Y_i \\
    \sum X_{i2} Y_i \\
    \vdots \\
    \sum X_{ip} Y_i \\
  \end{bmatrix}
\\
\Rightarrow \begin{bmatrix}
  	\beta_0 n + \beta_1 \sum X_{i1} + \beta_2 \sum X_{i2} + \cdots + \beta_p \sum X_{ip} \\
  	\beta_0 \sum X_{i1} + \beta_1 \sum X_{i1}^2 + \beta_2 \sum X_{i1} X_{i2 } + \cdots + \beta_p \sum X_{i1} X_{ip} \\
  	\beta_0 \sum X_{i2} + \beta_1 \sum X_{i2} X_{i1} + \beta_2 \sum X_{i2}^2 + \cdots + \beta_p \sum X_{i2} X_{ip} \\
  	\vdots \\
  	\beta_0 \sum X_{ip} + \beta_1 \sum X_{ip} X_{i1} + \beta_2 \sum X_{ip} X_{i2} + \cdots + \beta_p \sum X_{ip}^2 \\
  \end{bmatrix}
=
  \begin{bmatrix}
    \sum Y_{i} \\
    \sum X_{i1} Y_i \\
    \sum X_{i2} Y_i \\
    \vdots \\
    \sum X_{ip} Y_i \\
  \end{bmatrix} ,
\end{gather*}
where each $\sum$ indicates summation over all cases ($i = 1, 2, \ldots, n$).

As long as $\mathbf{X}^T \mathbf{X}$ is invertible, the least squares solution is $\mathbf{b} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}$. By the invertible matrix theorem, $\mathbf{X}^T \mathbf{X}$ is invertible whenever the columns of $\mathbf{X}$ are linearly independent.

\titledquestion{\ramsey 10.22}



\titledquestion{\ramsey 10.26}



\titledquestion{\ramsey 11.8}



\titledquestion{\ramsey 11.16}



\titledquestion{\ramsey 11.20}



\end{questions}

%\listoftodos

\end{document}